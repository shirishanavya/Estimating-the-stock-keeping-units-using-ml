# -*- coding: utf-8 -*-
"""Miniproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/143QBFJtAk9i-EAZTqZPucQFNcKItrAjw

# Importing the libraries
"""

import numpy as np
import pandas as pd

"""# Read the dataset"""

df=pd.read_csv('/content/train_0irEZ2H (1) (1).csv')

"""# Checking the dataset"""

df.head()

df.tail()

df.shape

df.info()

df.describe()

"""# Visualizing the data

***Scatter*** **plot**
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.scatter(df['units_sold'],df['total_price'])
plt.xlabel('units_sold')
plt.ylabel('total_price')
plt.title('Total price vs Units sold')
plt.show()

"""***Bar*** ***plot***"""

top_stores=df.groupby('store_id')['units_sold'].sum().sort_values(ascending=False).head(10)
plt.bar(top_stores.index,top_stores.values)
plt.xlabel('store_id')
plt.ylabel('units_sold')
plt.title('Top 10 stores by units sold')
plt.show()

"""***Histograms***"""

plt.hist(df['total_price'],bins=20)
plt.xlabel('Total price')
plt.ylabel('Frequency')
plt.title('Total Price Distribution')
plt.show()

"""***Heatmaps***"""

corr_matrix=df[['total_price','base_price','units_sold']].corr()
sns.heatmap(corr_matrix,annot=True,cmap='coolwarm',square=True)
plt.title('Correlation Heatmap')
plt.show()

"""# Analysing the data

**Univariate** **analysis**
"""

for col in df.columns:
  print(df[col].describe())
  plt.figure(figsize=(8,6))
  df[col].hist(bins=20)
  plt.title(col)
  plt.show()

"""**Multivariate** **Analysis**"""

from pandas.plotting import scatter_matrix
scatter_matrix(df[['total_price','base_price','units_sold']],figsize=(10,8))
plt.show()

"""# Data preprocessing

Handling the missing values
"""

categorical_cols=df.select_dtypes(include=['object']).columns
print(categorical_cols)

numerical_cols=df.select_dtypes(include=['int64','float64']).columns
print(numerical_cols)

df.isnull().sum()

df.drop(column_name=total_price, axis=1)

df['key']=df['week'].astype(str)+'-'+df['store_id'].astype(str)

df['key']

df=df.drop(['record_ID','week','store_id','sku_id','total_price','base_price','is_featured_sku','is_display_sku'],axis=1)

df=df.groupby('key').sum()

df

"""# Data visualization"""

df[:100].plot(figsize=(12,8))

"""# Splitting data into x and y"""

df['day_1']=df['units_sold'].shift(-1)
df['day_2']=df['units_sold'].shift(-2)
df['day_3']=df['units_sold'].shift(-3)
df['day_4']=df['units_sold'].shift(-4)

df

"""## Removing NaN data"""

df=df.dropna()

"""# Splitting data into train and test"""

from sklearn.model_selection import train_test_split

x=df[['day_1','day_2','day_3','day_4']]
y=df['units_sold']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

"""# Model building

**Linear** **Regression**
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error,r2_score

lr=LinearRegression()
lr.fit(x_train,y_train)
pred=lr.predict(x_test)
print("Mean Squared Error:",mean_squared_error(y_test,pred))
print("R2 Score:",r2_score(y_test,pred))

pred=lr.predict([[682.0,535.0,210.0,782.0]])
pred

"""**Random** **Forest** **Model**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error,r2_score

rf=RandomForestRegressor()

rf.fit(x_train,y_train)
pred=rf.predict(x_test)

print("Mean Squared Error:",mean_squared_error(y_test,pred))
print("R2 Score:",r2_score(y_test,pred))

pred=rf.predict([[682.0,535.0,210.0,782.0]])
pred

"""Decision tree regressor"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score
dt=DecisionTreeRegressor()
dt.fit(x_train,y_train)
pred=dt.predict(x_test)
print("Mean Squared Error:",mean_squared_error(y_test,pred))
print("R2 Score:",r2_score(y_test,pred))
print(accuracy_score(pred,y_test))

y_p=dt.predict([[682.0,535.0,210.0,782.0]])
y_p

"""# hyper parameter tunning

linear regression
"""

from sklearn.model_selection import GridSearchCV
param_grid={'fit_intercept':[True,False],'copy_X':[True,False]}
grid_search=GridSearchCV(lr,param_grid,cv=5)
grid_search.fit(x_train,y_train)

pred_cv=grid_search.predict(x_test)
print("Mean Square Error:",mean_squared_error(y_test,pred_cv))
print("R2 Score:",r2_score(y_test,pred_cv))

y_p=grid_search.predict([[682.0,535.0,210.0,782.0]])
y_p

"""**Random** **forest**"""

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.datasets import make_regression

x,y=make_regression(n_samples=1000,n_features=10,random_state=42)

n_estimators=[int(x) for x in np.linspace(start=50,stop=250,num=10)]
max_features=['auto','sqrt']
max_depth=[int(x) for x in np.linspace(0,120,num=20)]
max_depth.append(None)
min_samples_split=[2,5,10]
min_samples_leaf=[1,2,4]
bootstrap=[True,False]

random_grid={'n_estimators':n_estimators,
             'max_features':max_features,
             'max_depth':max_depth,
             'min_samples_split':min_samples_split,
             'min_samples_leaf':min_samples_leaf,
             'bootstrap':bootstrap}

print(random_grid)

from sklearn.model_selection import RandomizedSearchCV
rf_regressor=RandomForestRegressor()
rf_random=RandomizedSearchCV(estimator=rf_regressor,param_distributions=random_grid,n_iter=10,cv=3,verbose=2,random_state=0)
rf_random.fit(x_train,y_train)

y_pred=rf_random.predict(x_test)

print("Mean Square Error:",mean_squared_error(y_pred,y_test))
print("R2 score:",r2_score(y_test,y_pred))

y_p=rf_random.predict([[682.0,535.0,210.0,782.0]])
y_p

"""**Decision** **tree** **hyperparameter** **tunning**"""

from sklearn.model_selection import RandomizedSearchCV
param_dist={
    'max_depth':[None,5,10,15,20],
    'min_samples_split':[2,5,10],
    'min_samples_leaf':[1,2,4],
    'max_features':['auto','sqrt','log2']

}
tree=DecisionTreeRegressor()
dt=DecisionTreeRegressor()
dt_cv=RandomizedSearchCV(estimator=tree,param_distributions=param_dist,cv=5,n_iter=50,scoring="r2",verbose=2)
dt_cv.fit(x_train,y_train)

y_p=dt_cv.predict([[682.0,535.0,210.0,782.0]])
y_p

y_p=dt_cv.predict([[535.0,210.0,782.0,1357.0]])
y_p

"""XGBClassifier Model"""

pip install xgboost

import xgboost
xgb_regressor=xgboost.XGBRegressor()
xgb_regressor.fit(x_train,y_train)
y_pred=xgb_regressor.predict(x_test)

print("R Sq. Score for XGBoost :",xgb_regressor.score(x_test,y_test))

"""Evaluating performance  of  the  model  using  randomized  search  cv  and saving  the  model"""

rf_random.best_params_

best_random=rf_random.best_estimator_

y_pred=best_random.predict(x_test)

print("R2 Score for Random Forest Regression :",best_random.score(x_test,y_test))

print("Mean Squared Error:",mean_squared_error(y_pred,y_test))

#save the model
import pickle
pickle.dump(rf_regressor,open('model.pkl','wb'))

#rf_regressor
rf_regressor.fit(x_train,y_train)
features=np.array([[682.0,535.0,210.0,782.0]])
print(rf_regressor.predict(features))